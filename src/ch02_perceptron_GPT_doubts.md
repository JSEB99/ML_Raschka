# ğŸ§  PerceptrÃ³n - GuÃ­a TeÃ³rica Completa para Principiantes

Este documento resume los conceptos esenciales del algoritmo **PerceptrÃ³n**, con Ã©nfasis en teorÃ­a, intuiciÃ³n y buenas prÃ¡cticas. Ideal para estudiantes de machine learning que estÃ¡n dando sus primeros pasos.

---

## ğŸ” Â¿QuÃ© es un perceptrÃ³n?

Un **perceptrÃ³n** es un modelo de clasificaciÃ³n binaria supervisado que aprende a separar clases linealmente separables mediante el ajuste de pesos asociados a las caracterÃ­sticas (features) de entrada.

---

## âš™ï¸ Componentes principales

- `w_` â†’ Vector de pesos (un valor por cada caracterÃ­stica).
- `b_` â†’ Bias (umbral), un escalar.
- `eta` â†’ Tasa de aprendizaje.
- `n_iter` â†’ NÃºmero de Ã©pocas (pasadas sobre el dataset).
- `errors_` â†’ Lista que guarda el nÃºmero de errores por Ã©poca.

---

## ğŸ§® CÃ¡lculo del net input y predicciÃ³n

### ğŸ§¾ FÃ³rmula del net input:

\[
z = \mathbf{w} \cdot \mathbf{x} + b
\]

- \( \mathbf{w} \): pesos
- \( \mathbf{x} \): vector de entrada (ejemplo)
- \( b \): bias
- \( \cdot \): producto punto

### ğŸ“¤ PredicciÃ³n:

\[
\hat{y} = 
\begin{cases}
1 & \text{si } z \geq 0 \\
0 & \text{si } z < 0
\end{cases}
\]

---

## ğŸ”§ Regla de actualizaciÃ³n

Cuando el perceptrÃ³n se equivoca, se actualizan los pesos y bias:

\[
\text{update} = \eta \cdot (y - \hat{y})
\]

\[
\mathbf{w} \leftarrow \mathbf{w} + \text{update} \cdot \mathbf{x}
\]
\[
b \leftarrow b + \text{update}
\]

Si predice correctamente, el error es 0 y no hay actualizaciÃ³n.

---

## ğŸ“‰ Conteo de errores

Cada vez que hay un error, se suma 1:

```python
errors += int(update != 0.0)
```

* `int(True)` = 1
* `int(False)` = 0

AsÃ­ se construye la lista `errors_`, que contiene cuÃ¡ntos errores hubo en cada Ã©poca.

---

## ğŸ“¦ Estructura del dataset con `zip(X, y)`

`X`: matriz de forma `(n_samples, n_features)`
`y`: vector de etiquetas de forma `(n_samples,)`


```Python
for xi, target in zip(X, y):
    # xi es una fila de X, target es su etiqueta correspondiente
```

Ejemplo:

```python
X = [[1, 2], [3, 4], [5, 6]]
y = [0, 1, 0]

zip(X, y) â†’ ([1,2], 0), ([3,4], 1), ([5,6], 0)
```

---

## âš ï¸ Â¿Por quÃ© NO inicializar pesos en cero?

Inicializar con ceros genera problemas:

* El vector de pesos inicial no tiene direcciÃ³n definida.
* Tras la primera actualizaciÃ³n:

  $$
  \mathbf{w} = \eta \cdot \mathbf{x}
  $$

  Es decir, **la direcciÃ³n de los pesos se alinea con el primer ejemplo** mal clasificado.
* Esto puede causar que el modelo aprenda de forma **sesgada** hacia ese primer ejemplo.

âœ… SoluciÃ³n: inicializar `w_` con **valores aleatorios pequeÃ±os**, por ejemplo:

```python
rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])
```

Esto permite que `w_` tenga una **direcciÃ³n aleatoria inicial distinta de cero**, ayudando al aprendizaje.

---

## ğŸ“ Â¿QuÃ© significa direcciÃ³n de un vector?

Un vector tiene:

1. Magnitud (longitud)
2. DirecciÃ³n (hacia dÃ³nde apunta)

### El vector **\[0, 0, ..., 0]** (vector cero):

* Tiene magnitud = 0
* âŒ **No tiene direcciÃ³n**
* âš ï¸ Por eso no puedes calcular Ã¡ngulos ni compararlo con otros vectores

### Si:

$$
\mathbf{w} = \alpha \cdot \mathbf{x}, \quad \alpha \neq 0
$$

Entonces:

* Tienen la **misma direcciÃ³n** (o la opuesta si $\alpha < 0$)
* Esto se llama **colinealidad**

---

## ğŸ§  ConclusiÃ³n final

* El perceptrÃ³n es un modelo simple pero poderoso para clasificaciÃ³n binaria.
* Los pesos deben inicializarse con pequeÃ±os valores aleatorios, **no ceros**.
* La actualizaciÃ³n depende del error entre la etiqueta real y la predicciÃ³n.
* El modelo ajusta sus pesos en la direcciÃ³n de los ejemplos mal clasificados.
* El bias permite mover la frontera de decisiÃ³n sin depender de las features.

---

## ğŸ“Œ Recomendaciones

* Usar `eta` pequeÃ±os como 0.01 o 0.001
* Visualizar la curva de errores (`errors_`) para ver si el modelo aprende
* Normalizar los datos si los valores de las features varÃ­an mucho
* Comprobar que `X` y `y` tengan la misma longitud antes de entrenar
